{
    "_": [
        "RAG/TAG Tiger inference provider config",

        "There is a list of models in models.json, with simple canonical names",
        "like 'codellama-70b`. (Only '-instruct' and '-chat' models are",
        "used by the program, so one of those suffixes is implied).",

        "A given provider will only support a subset of the models, and",
        "may use different names internally to identify them. The",
        "provider configurations below contain a list of the models",
        "they offer and mappings to the internal names.",

        "This gives a provider-independent way to select models for RAG,",
        "which is the '--llm-preset' command line option. RAG/TAG Tiger",
        "will detect available providers by finding their API keys in the",
        "environment, then choose a provider for each model. Priority",
        "is based on list order, so place your cheapest/fastest/preferred",
        "providers first.",

        "Check the README for more information about inference providers",
        "in general. Only a few are listed here, basically just the ones",
        "I was testing. If you add a new configuration, please submit a",
        "pull request!"
    ],

    "providers":
    {
        "openai": {
            "name":                 "OpenAI",
            "website":              "https://openai.com",
            "connection": {       
                "api_key":          "OPENAI_API_KEY",
                "protocol":         "openai"
            },      
            "model_names": {       
                "gpt-3.5":          "gpt-3.5-turbo-instruct",
                "gpt-4":            "gpt-4"
            }
        },

        "together": {
            "name":                 "together.ai",
            "website":              "https://together.ai",
            "connection": {       
                "api_key":          "TOGETHERAI_API_KEY",
                "protocol":         "openai",
                "endpoint":         "https://api.together.xyz"
            },
            "model_names": {
                "codellama-34b":    "codellama/CodeLlama-34b-Instruct-hf",
                "falcon-40b":       "togethercomputer/falcon-40b-instruct",
                "llama-2-7b":       "togethercomputer/Llama-2-7B-32K-Instruct",
                "llama-2-70b":      "togethercomputer/llama-2-70b-chat",
                "llama-python-34b": "codellama/CodeLlama-34b-Python-hf",
                "llama-python-70b": "codellama/CodeLlama-70b-Python-hf",
                "mistral-7b":       "mistralai/Mistral-7B-Instruct-v0.2",
                "mixtral-8x7b":     "mistralai/Mixtral-8x7B-Instruct-v0.1",
                "phind-34b":        "Phind/Phind-CodeLlama-34B-v2",
                "wizard-python-34b":"WizardLM/WizardCoder-Python-34B-V1.0",
                "yi-34b":           "zero-one-ai/Yi-34B-Chat"
            }
        },

        "replicate": {
            "name":                 "Replicate",
            "website":              "https://replicate.com",
            "connection": {       
                "api_key":          "REPLICATE_API_TOKEN",
                "protocol":         "replicate"
            },
            "model_names": {
                "codellama-34b":    "meta/codellama-34b-instruct",
                "codellama-70b":    "meta/codellama-70b-instruct:a279116fe47a0f65701a8817188601e2fe8f4b9e04a518789655ea7b995851bf",
                "falcon-40b":       "joehoover/falcon-40b-instruct",
                "llama-2-7b":       "meta/llama-2-7b-chat",
                "llama-2-70b":      "meta/llama-2-70b-chat",
                "mistral-7b":       "mistralai/mistral-7b-instruct-v0.2",
                "mixtral-8x7b":     "mistralai/mixtral-8x7b-instruct-v0.1",
                "yi-34b":           "01-ai/yi-34b-chat"
            }
        },

        "fireworks": {
            "name":                 "fireworks.ai",
            "website":              "https://fireworks.ai",
            "connection": {
                "api_key":          "FIREWORKS_API_KEY",
                "protocol":         "openai",
                "endpoint":         "https://api.fireworks.ai/inference/v1"
            },
            "model_names": {
                "codellama-34b":    "accounts/fireworks/models/llama-v2-34b-code-instruct",
                "codellama-70b":    "accounts/fireworks/models/llama-v2-70b-code-instruct",
                "llama-2-7b":       "accounts/fireworks/models/llama-v2-7b-chat",
                "llama-2-70b":      "accounts/fireworks/models/llama-v2-70b-chat",
                "mistral-7b":       "accounts/fireworks/models/mistral-7b-instruct",
                "mixtral-8x7b":     "accounts/fireworks/models/mixtral-8x7b-instruct"
            }
        },

        "perplexity":
        {
            "name":                 "Perplexity",
            "website":              "https://perplexity.ai",
            "connection": {
                "api_key":          "PERPLEXITYAI_API_KEY",
                "protocol":         "perplexity"
            },
            "model_names": {
                "codellama-34b":    "codellama-34b-instruct",
                "codellama-70b":    "codellama-70b-instruct",
                "llama-2-70b":      "llama-2-70b-chat",
                "mistral-7b":       "mistral-7b-instruct",
                "mixtral-8x7b":     "mixtral-8x7b-instruct"
            }
        },

        "google":
        {
            "name":                 "Google",
            "website":              "https://deepmind.google",
            "connection": {       
                "api_key":          "GOOGLE_API_KEY",
                "protocol":         "google"
            },
            "model_names": {
                "palm":             "models/text-bison-001"
            }
        },

        "gemini":
        {
            "name":                 "Google",
            "website":              "https://deepmind.google",
            "connection": {       
                "api_key":          "GEMINI_API_KEY",
                "protocol":         "google"
            },
            "model_names": {
                "gemini-pro":       "models/gemini-pro"
            }
        }
    }
}
